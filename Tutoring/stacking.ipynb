{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_RF = RandomForestClassifier()\n",
    "model_DT = DecisionTreeClassifier()\n",
    "model_LR = LogisticRegression()\n",
    "model_LGBM = LGBMClassifier()\n",
    "model_XGB = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./타이타닉/train.csv\")\n",
    "X_test = pd.read_csv(\"./타이타닉/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./타이타닉/y_test.csv\")\n",
    "y_train =df[\"Survived\"]\n",
    "X_train = df.drop(\"Survived\", axis=1)\n",
    "y_test = y_test[\"Survived\"]\n",
    "\n",
    "X_train = X_train.select_dtypes(exclude=\"object\")\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.select_dtypes(exclude=\"object\")\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "X_train_re = X_train.copy()\n",
    "X_test_re = X_test.copy()\n",
    "\n",
    "X_train_re.columns = list(range(1,len(X_train.columns)+1))\n",
    "X_test_re.columns = list(range(1,len(X_train.columns)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별모델 내부에서 CV 적용해 Stacking하는 함수 구현(k=5)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def get_stacking_datasets(model):\n",
    "\n",
    "    # 최종 메타 모델이 사용할 학습 데이터 반환을 위해서 넘파이 배열을 0으로 만들어서 초기화\n",
    "    train_fold_pred = np.zeros((X_train_re.shape[0], 1)) # 2차원으로\n",
    "    test_pred = np.zeros((X_test_re.shape[0], 5)) # n_splits=5\n",
    "    print(model.__class__.__name__, '모델 시작')\n",
    "    \n",
    "    for folder_counter, (train_idx, valid_idx) in enumerate(KFold(n_splits=5, shuffle=True, random_state=42).split(X_train_re)):\n",
    "        # 개별 모델 내부에서 학습하고 1개의 fold로 예측할 데이터 셋 추출\n",
    "        print(f\" Fold 횟수 : {folder_counter+1}\")\n",
    "        X_train_ = X_train_re.iloc[train_idx]\n",
    "        y_train_ = y_train.iloc[train_idx]\n",
    "        X_test_ = X_train_re.iloc[valid_idx]\n",
    "        \n",
    "        # 개별 모델이 학습한 후 1개의 fold데이터셋으로 예측값 반환 후 최종 메타모델이 학습할 데이터셋에 첨가\n",
    "        model.fit(X_train_, y_train_)\n",
    "        train_fold_pred[valid_idx, :] = model.predict(X_test_).reshape(-1,1)\n",
    "        # 개별 모델이 원본 데이터셋의 검증 데이터셋을 기반으로 예측 결과값 반환 후 최종 메타모델이 검증할 데이터셋에 첨가\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_re)\n",
    "    \n",
    "    # 개별모델안에서 테스트 데이터셋을 기반으로 예측한 결과값들 mean취해주고 2차원으로 바꾸어주기\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 모델 시작\n",
      " Fold 횟수 : 1\n",
      " Fold 횟수 : 2\n",
      " Fold 횟수 : 3\n",
      " Fold 횟수 : 4\n",
      " Fold 횟수 : 5\n",
      "DecisionTreeClassifier 모델 시작\n",
      " Fold 횟수 : 1\n",
      " Fold 횟수 : 2\n",
      " Fold 횟수 : 3\n",
      " Fold 횟수 : 4\n",
      " Fold 횟수 : 5\n",
      "RandomForestClassifier 모델 시작\n",
      " Fold 횟수 : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leeju\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\leeju\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 횟수 : 2\n",
      " Fold 횟수 : 3\n",
      " Fold 횟수 : 4\n",
      " Fold 횟수 : 5\n",
      "LGBMClassifier 모델 시작\n",
      " Fold 횟수 : 1\n",
      " Fold 횟수 : 2\n",
      " Fold 횟수 : 3\n",
      " Fold 횟수 : 4\n",
      " Fold 횟수 : 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LR_train, LR_test = get_stacking_datasets(model_LR)\n",
    "DT_train, DT_test = get_stacking_datasets(model_DT)\n",
    "RF_train, RF_test = get_stacking_datasets(model_RF)\n",
    "LGBM_train, LGBM_test = get_stacking_datasets(model_LGBM)\n",
    "\n",
    "new_x_train = np.concatenate((LR_train, DT_train, RF_train,LGBM_train), axis = 1)\n",
    "new_x_test = np.concatenate(( LR_test, DT_test,  RF_test,LGBM_test), axis = 1)\n",
    "\n",
    "# # meta learner\n",
    "model_RF.fit(new_x_train, y_train) # 최종모델 XGB\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_hat_train = pd.DataFrame(model_RF.predict(new_x_train))\n",
    "y_hat = pd.DataFrame(model_RF.predict(new_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SV</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  acc_train  auc_train  acc_test  precision  recall  f1_score  AUC_test\n",
       "0    SV       0.73       0.69      0.64       0.51    0.47      0.49      0.61"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdict={'model':[], \"acc_train\":[], \"auc_train\":[], 'acc_test':[],'precision':[],'recall':[],'f1_score':[], 'AUC_test':[]}\n",
    "\n",
    "results_train  = (round(accuracy_score(y_train,y_hat_train),2),round(roc_auc_score(y_train,y_hat_train),2))\n",
    "\n",
    "results = (round(accuracy_score(y_test,y_hat),2),\n",
    "                round(precision_score(y_test,y_hat),2),\n",
    "                round(recall_score(y_test,y_hat),2),\n",
    "                round(f1_score(y_test,y_hat),2),\n",
    "                round(roc_auc_score(y_test,y_hat),2))\n",
    "\n",
    "rdict['model'].append(\"SV\"); \n",
    "rdict['acc_train'].append(results_train[0])\n",
    "rdict['auc_train'].append(results_train[1])\n",
    "rdict['acc_test'].append(results[0])\n",
    "rdict['precision'].append(results[1])\n",
    "rdict['recall'].append(results[2])\n",
    "rdict['f1_score'].append(results[3])\n",
    "rdict['AUC_test'].append(results[4])\n",
    "\n",
    "rdf_stacking = pd.DataFrame(data=rdict)\n",
    "rdf_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eeef853a245549128f6729d501dfc17c524bc2eff54c3e26aeb087494d03671c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
